#
# 목적 : 아파트 실거래 데이터
# 데이터 소스 : https://www.data.go.kr/ 
# 데이터 저장 위치 : aws rds - mariadb 
#        Table : apart_real_cost
# 수집 방법 : aws lambda 프로그램
# 수집 주기 : 1달에 1번  
#      수집 scheduler : aws Event_bridge
python version : Python 3.9.16

$ mkdir open_api
$ cd open_api
$ python3 -m venv open_env
$ source ./open_env/bin/activate
$ pip install mysql-connector-python
$ pip install requests
$ pip install bs4
$ pip install pandas
$ pip install lxml
$ pip install pyarrow

$ pip list
Package                Version
---------------------- ------------
beautifulsoup4         4.12.3
boto3                  1.34.23
botocore               1.34.23
bs4                    0.0.2
certifi                2023.11.17
charset-normalizer     3.3.2
idna                   3.6
install                1.3.5
jmespath               1.0.1
lxml                   5.1.0
mysql-connector-python 8.3.0
numpy                  1.26.3
pandas                 2.2.0
pip                    23.3.2
pyarrow                14.0.2
python-dateutil        2.8.2
pytz                   2023.3.post1
requests               2.31.0
s3transfer             0.10.0
setuptools             59.6.0
six                    1.16.0
soupsieve              2.5
tzdata                 2023.4
urllib3                1.26.18


$ vi api_test.py
import requests

url = 'http://openapi.molit.go.kr:8081/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcAptTrade'
params ={'serviceKey' : '43ShfBW0KpotiijFbKbxPN5RvWndjxuDkKpKKirq2kSsLcKXgip5nbIAr6RIoQ+B7sgo4E21wLdNBSrwuCztxQ==', 'LAWD_CD' : '11110', 'DEAL_YMD' : '202312' }

response = requests.get(url, params=params)
print(response.content)

$ python3 api_test.py

$ vi apart_real_sales.py
import requests
from bs4 import BeautifulSoup
import pandas as pd
import urllib.request

req = urllib.request
d_key = '43ShfBW0KpotiijFbKbxPN5RvWndjxuDkKpKKirq2kSsLcKXgip5nbIAr6RIoQ%2BB7sgo4E21wLdNBSrwuCztxQ%3D%3D'



def getRTMSDataSvcAptTrade(LAWD_CD, DEAL_YMD, serviceKey):
    url = "http://openapi.molit.go.kr:8081/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcAptTrade"
    url = url + "?&LAWD_CD=" + LAWD_CD
    url = url + "&DEAL_YMD=" + DEAL_YMD
    url = url + "&serviceKey=" + serviceKey

    xml = req.urlopen(url)
    result = xml.read()
    soup = BeautifulSoup(result, 'lxml-xml')

    items = soup.findAll("item")
    aptTrade = pd.DataFrame()

    for item in items:
        dealAmount = item.find("거래금액").text
        dealYear = item.find("년").text
        dong = item.find("법정동").text
        apartmentName = item.find("아파트").text
        dealMonth = item.find("월").text
        dealDay = item.find("일").text
        areaForExclusiveUse = item.find("전용면적").text
        regionalCode = item.find("지역코드").text
        floor = item.find("층").text

        try:
            jibun = item.find("지번").text
        except:
            jibun = ""
        try:
            buildYear = item.find("건축년도").text
        except:
            buildYear = ""

        temp = pd.DataFrame(([
            [dealAmount, buildYear, dealYear, dong, apartmentName, dealMonth, dealDay, areaForExclusiveUse, jibun,
             regionalCode, floor]]),
                            columns=["dealAmount", "buildYear", "dealYear", "dong", "apartmentName", "dealMonth",
                                     "dealDay", "areaForExclusiveUse", "jibun", "regionalCode", "floor"])

        aptTrade = pd.concat([aptTrade, temp])

    aptTrade = aptTrade.reset_index(drop=True)
    return aptTrade

print(getRTMSDataSvcAptTrade('11110', '202304', d_key))

$ python3 apart_real_sales.py

# database 에 아파트 실거래 정보를 저장한다. 


# 엑셀 법정동코드 데이터 핸들링 : 
#엑셀데이터 처리 
1. 구코드  : MID(A3,1,5)  
2. 시도   : LEFT(B2, FIND(" ", B2) - 1)
3. 군구   : MID(B2, FIND(" ", B2) + 1, FIND(" ", B2, FIND(" ", B2) + 1) - FIND(" ", B2) - 1)
4. 동     : RIGHT(B2, LEN(B2) - FIND(" ",B2, FIND(" ", B2) + 1))

# 법정동코드 테이블 생성
create table law_code_info(
    law_code varchar(10) comment '법정동코드',
    law_area_name varchar(300) comment '법정동명',
    gucode varchar(5) comment '구코드',
    sido varchar(100) comment '시도',
    gungu varchar(100) comment '군구',
    dong varchar(100) comment '동리',
    create_at datetime comment '입력일시'
);

# 법정동 데이터 insert 하기 
"insert into law_code_info (law_code, law_area_name, gucode, sido, gungu, dong, create_at)
values ('"&A4&"','"&B4&"','"&C4&"','"&D4&"','"&E4&"','"&F4&"',now());"


# 공공데이터에서 가져온 아파트 실거래값 저장할 table : apart_real_cost 생성한다. 
create table apart_real_cost
(
    deal_amt       varchar(40) comment '거래금액',
    build_year     varchar(4) comment '건축년도',
    deal_year      varchar(4) comment '년',
    dong           varchar(40) comment '법정동',
    apart_nm       varchar(40) comment '아파트명',
    deal_month     varchar(2) comment '계약월',
    deal_day       varchar(6) comment '일',
    area_ex_use    varchar(20) comment '전용면적',
    jibun          varchar(10) comment '지번',
    regional_code  varchar(5) comment '지역코드',
    floor          varchar(4) comment '층',
    cnl_deal_type  varchar(1) comment '해제여부',
    cnl_deal_day   varchar(8) comment '해제사유발생일',
    req_gbn        varchar(10) comment '거래유형',
    rdealer_rawdnm varchar(150) comment '중개사소재지',
    reg_date       varchar(8) comment '등기일자',
    create_at      timestamp comment '등록일시' ) ;

# 아파트 실거래가를 Mariadb 에 저장한다. 
$ vi apartToDB.py

import requests
from bs4 import BeautifulSoup
import urllib.request
import pandas as pd
import mysql.connector
from mysql.connector import errorcode


req = urllib.request
d_key = '43ShfBW0KpotiijFbKbxPN5RvWndjxuDkKpKKirq2kSsLcKXgip5nbIAr6RIoQ%2BB7sgo4E21wLdNBSrwuCztxQ%3D%3D'

#Mysql 데이터 입력하기 
def insert_data_into_mysql(dataframe):
	    # MySQL 연결 설정
	    try:
	        connection = mysql.connector.connect(
	            host='datastory-fc.cgfpdcibdeds.ap-northeast-2.rds.amazonaws.com',
	            user='pipeline',
	            password='Epdlxj12#',
	            database='pipelinedb'
	        )
	
	        cursor = connection.cursor()
	
	        # MySQL 테이블에 데이터프레임의 데이터를 삽입
	        for index, row in dataframe.iterrows():
	            sql = """
									INSERT INTO apart_real_cost (
                        deal_amt, build_year, deal_year, dong, apart_nm, deal_month,
                        deal_day, area_ex_use, jibun, regional_code, floor
	                ) VALUES (
	                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
	                )
	            """
	            values = (
	                row['dealAmount'], row['buildYear'], row['dealYear'], row['dong'],
	                row['apartmentName'], row['dealMonth'], row['dealDay'], row['areaForExclusiveUse'],
	                row['jibun'], row['regionalCode'], row['floor']
	            )
	            cursor.execute(sql, values)
	
	        # 변경사항을 커밋
	        connection.commit()
	
	    except mysql.connector.Error as err:
	        if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:
	            print("Access denied: Check your MySQL username and password")
	        elif err.errno == errorcode.ER_BAD_DB_ERROR:
	            print("Database does not exist")
	        else:
	            print("Error: {}".format(err))
	    finally:
	        # 커넥션 닫기
	        if 'connection' in locals() and connection.is_connected():
	            cursor.close()
	            connection.close()

def getRTMSDataSvcAptTrade(LAWD_CD, DEAL_YMD, serviceKey):
    url = "http://openapi.molit.go.kr:8081/OpenAPI_ToolInstallPackage/service/rest/RTMSOBJSvc/getRTMSDataSvcAptTrade"
    url = url + "?&LAWD_CD=" + LAWD_CD
    url = url + "&DEAL_YMD=" + DEAL_YMD
    url = url + "&serviceKey=" + serviceKey

    xml = req.urlopen(url)
    result = xml.read()
    soup = BeautifulSoup(result, 'lxml-xml')

    items = soup.findAll("item")
    aptTrade = pd.DataFrame()

    for item in items:
        dealAmount = item.find("거래금액").text
        dealYear = item.find("년").text
        dong = item.find("법정동").text
        apartmentName = item.find("아파트").text
        dealMonth = item.find("월").text
        dealDay = item.find("일").text
        areaForExclusiveUse = item.find("전용면적").text
        regionalCode = item.find("지역코드").text
        floor = item.find("층").text

        try:
            jibun = item.find("지번").text
        except:
            jibun = ""

        try:
            buildYear = item.find("건축년도").text
        except:
            buildYear = ""

        temp = pd.DataFrame(([
            [dealAmount, buildYear, dealYear, dong, apartmentName, dealMonth, dealDay, areaForExclusiveUse, jibun,
             regionalCode, floor]]),
                            columns=["dealAmount", "buildYear", "dealYear", "dong", "apartmentName", "dealMonth",
                                     "dealDay", "areaForExclusiveUse", "jibun", "regionalCode", "floor"])

        aptTrade = pd.concat([aptTrade, temp])

    aptTrade = aptTrade.reset_index(drop=True)
    return aptTrade




 
insert_data_into_mysql(getRTMSDataSvcAptTrade('11110', '202312', d_key))
insert_data_into_mysql(getRTMSDataSvcAptTrade('11350', '202312', d_key))

# 위 python 프로그램을 패킹하여 lambda 에 등록한다. 
$ mv apartToDB.py lambda_function.py
$ deactivate
$ cd open_env/lib/python3.9/site-packages/
$ zip -r ../../../../apart_real_cost.zip .
$ cd ../../../../
$ zip apart_realcost_package.zip lambda_function.py
$ aws s3 cp apart_realcost_package.zip s3://fc-storydata/
